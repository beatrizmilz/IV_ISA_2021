---
title: "Report - IV ISA 2021"
author: "Beatriz Milz"
date: "08/12/2020"
output: html_document
---
## Preparing the dataset

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###  Load packages

```{r}
library(magrittr)
```

```{r}
# install.packages("devtools")
# devtools::install_github("beatrizmilz/ComitesBaciaSP")
library(ComitesBaciaSP)
```

### Create a df with only the committes that are part of the MMP

```{r}
comites_mmp <- ComitesBaciaSP::comites_sp %>% 
 dplyr::filter(macrometropole_daee == TRUE) 

siglas_mmp <- comites_mmp %>% dplyr::pull(sigla_comite)
```

## Download HTML pages (important to have a backup)


```{r}
url_comites <- comites_mmp %>% 
  dplyr::mutate(url = glue::glue("http://www.sigrh.sp.gov.br/cbh{sigla_comite}/atas"))

for (i in 1:length(url_comites)){
  
  url <- url_comites %>% dplyr::slice(i)  %>% dplyr::pull(url) 
  sigla_comite <- url_comites %>% dplyr::slice(i)  %>% dplyr::pull(sigla_comite) 
  
    httr::GET(url, httr::write_disk(path = glue::glue("data/html/{sigla_comite}-{Sys.Date()}.html")))
  
}

```



## Scrape and download the df with the comitte plenuns information

```{r eval=FALSE, include=TRUE}
download_df <- function(sigla_comite, path = "data/df_minutes/raw") {
  
  file_name <-
    here::here(path,
               glue::glue("{sigla_comite}-{Sys.Date()}.Rds"))
  
  fs::dir_create(path)
  
  
  ComitesBaciaSP::obter_tabela_atas_comites(sigla_comite) %>%
    readr::write_rds(file = file_name)
  
  print(glue::glue("Arquivo baixado: {file_name}"))
}

purrr::map(.x = siglas_mmp, download_df)

```

### Get status code - THIS TAKES SOME TIME

```{r eval=FALSE, include=TRUE}
get_status_code <-
  function(file,
           write_path = "data/df_minutes/status_code") {

    file_read <- file
    
    fs::dir_create(write_path)
    
    

    
    file_save <- here::here(write_path, fs::path_file(file))
    

    if(!file.exists(file_save)){
     readr::read_rds(file_read) %>%
      dplyr::mutate(link_ata_status = purrr::map_dbl(
        url_link,
        purrr::possibly(~ httr::status_code(httr::GET(.x)), otherwise = NA)
      )) %>%
      saveRDS(file = file_save)
 
    
    
    print(glue::glue("Arquivo baixado: {file_save}")) 
    } else {
    print(glue::glue("Arquivo não baixado pois já existe: {file_save}"))   
    }
    
    
  }


```



```{r eval=FALSE, include=TRUE}
path_raw <- "data/df_minutes/raw"

files_get_status <- list.files(path_raw, full.names = TRUE)

get_status_code(files_get_status[1])
beepr::beep(1)
get_status_code(files_get_status[2])
beepr::beep(1)
get_status_code(files_get_status[3])
beepr::beep(1)
get_status_code(files_get_status[4])
beepr::beep(1)
get_status_code(files_get_status[5])
beepr::beep(1)
get_status_code(files_get_status[6])
beepr::beep(1)
get_status_code(files_get_status[7])
beepr::beep(1)
get_status_code(files_get_status[8])
beepr::beep(1)
beepr::beep(2)

```



### Read all files into a single dataframe

```{r eval=FALSE, include=TRUE}
path <- "data/df_minutes/status_code"

dataset <- list.files(path, full.names = TRUE) %>%
  purrr::map_dfr(.f = readr::read_rds)

readr::write_rds(dataset,
                 glue::glue("data/dataset_df_minutes-{Sys.Date()}.Rds"))
```

### Explore the dataset

```{r}
dataset <- readr::read_rds("data/dataset_df_minutes-2020-12-08.Rds")
dplyr::glimpse(dataset)
```

### Prepare to Download files/minutes


```{r}
dataset_formatado <- dataset   %>%
  dplyr::mutate(
    formato_link = dplyr::case_when(
      is.na(url_link) ~ "Ata não disponibilizada",
      TRUE ~ stringr::str_extract(url_link, pattern = "(.doc|.docx|.pdf|.html|.htm|.jpg|.pd)$|drive.google")
    )
  ) %>%
  dplyr::left_join(ComitesBaciaSP::comites_sp) %>%
  dplyr::select(-numero_municipios,-macrometropole_daee,-bacia_hidrografica)


dataset_formatado %>% dplyr::count(formato_link)

```

### Filter dataset to download
```{r}
dataset_download <- dataset_formatado %>%
    dplyr::filter(link_ata_status == 200,
                  !is.na(link_ata_status)
                  ) %>%
      dplyr::mutate(
        nome_arquivo = fs::path_file(url_link),
        nome_arquivo_salvar =
          glue::glue("data/minutes_files/{sigla_comite}/{sigla_comite}-{data_reuniao}-{numero_link}-{nome_arquivo}"),
        nome_arquivo_curto = glue::glue("{sigla_comite}-{data_reuniao}-{numero_link}-{nome_arquivo}"),
        path = fs::path_dir(nome_arquivo_salvar)
      ) %>% 
  dplyr::distinct(n_ugrhi, data_reuniao, url_link, .keep_all = TRUE)

readr::write_rds(dataset_download, file = glue::glue("data/dataset_df_minutes_download_{Sys.Date()}.Rds"))
```

### Download all the files in dataset_download

```{r eval=FALSE, include=TRUE}
source("R/download_files.R", encoding = "UTF-8")
download_files(dataset_download)
length(list.files("data/minutes_files/", recursive = TRUE))
```
